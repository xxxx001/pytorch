skip:
  # https://github.com/pytorch/torchdynamo/issues/101
  - detectron2_maskrcnn
  # https://github.com/pytorch/torchdynamo/issues/145
  - fambench_xlmr
  # TIMEOUT, https://github.com/pytorch/pytorch/issues/98467
  - tacotron2
  # Error: RelaxedUnspecConstraint(L['input_ids'].size()[0]) - inferred constant (4)
  - hf_Bert
  # Error: RelaxedUnspecConstraint(L['input_ids'].size()[0]) - inferred constant (4)
  - hf_Bert_large
  # takes too long, extreme slowdown (< .001)
  - maml
  # Failing in eager mode
  - clip
  # multi gpu not always available in benchmark runners
  - simple_gpt_tp_manual

device:
  cpu:
    # OOMs
    - hf_T5_generate
    # model is CUDA only
    - cm3leon_generate
    # timeout
    - nanogpt
    # timeout
    - sam
    # model is CUDA only
    - llama_v2_7b_16h
    # flaky
    - stable_diffusion
    # requires FBGEMM, CUDA only
    - torchrec_dlrm
    - simple_gpt
    # works on cuda, accuracy failure on cpu
    - hf_Whisper
    - stable_diffusion_text_encoder

  cuda:
    # only works on CPU
    - gat
    - gcn
    - sage

test:
  train:
    # not designed for training
    - pyhpc_equation_of_state
    - pyhpc_isoneutral_mixing
    - pyhpc_turbulent_kinetic_energy
    - maml
    - llama
    - llama_v2_7b_16h
    - simple_gpt
    # doesnt fit in memory
    - phi_1_5
    # detectron2 benchmarks
    - detectron2_fasterrcnn_r_101_c4
    - detectron2_fasterrcnn_r_101_dc5
    - detectron2_fasterrcnn_r_101_fpn
    - detectron2_fasterrcnn_r_50_c4
    - detectron2_fasterrcnn_r_50_dc5
    - detectron2_fasterrcnn_r_50_fpn
    - detectron2_maskrcnn_r_101_c4
    - detectron2_maskrcnn_r_101_fpn
    - detectron2_maskrcnn_r_50_fpn

control_flow:
  - cm3leon_generate
  - detectron2_fcos_r_50_fpn
  - fastNLP_Bert
  - hf_Longformer
  - hf_Reformer
  - hf_T5_generate
  - opacus_cifar10
  - speech_transformer

# Models that should only run in --multiprocess mode
multiprocess:
  - simple_gpt

accuracy:
  large_models:
    # Models too large to have eager, dynamo and fp64_numbers simultaneosuly
    # even for 40 GB machine. We have tested accuracy for smaller version of
    # these models
    - hf_GPT2_large
    - hf_T5_large
    - timm_vision_transformer_large
    # accuracy https://github.com/pytorch/pytorch/issues/93847
    - maml
    - llama_v2_7b_16h
    - Background_Matting
    - stable_diffusion_unet

  eager_not_deterministic:
    # Models that deterministic algorithms can not be turned on for eager mode.
    - Background_Matting
